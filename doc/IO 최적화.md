## I/O 최적화

분산 정렬 시스템에서 I/O(Input/Output) 최적화란, CPU 연산보다 수천 배 느린 저장장치 접근을 최대한 효율화하여 전체 처리율을 극대화하는 설계 방식을 의미함.
동일한 데이터를 더 빠르게 읽고 쓸 수 있도록 데이터 전송 경로, 접근 패턴, 버퍼링 구조, 동기화 방식 등을 최적화하는 것이다.

### 1. 기본 원리

현대 시스템에서 CPU의 연산 속도(수십~수백 GB/s)는 SSD나 HDD의 I/O 속도(수백 MB/s~수 GB/s)에 비해 수백 배 이상 빠름.
이로 인해 프로그램의 처리 속도는 대부분 **I/O 병목(I/O Bottleneck)**에 의해 결정된다.
이를 해소하기 위해, I/O 최적화는 다음 세 가지 방향에서 수행된다.

-   **대역폭 활용:** 장치가 낼 수 있는 최대 순차 전송 속도를 유지

-   **지연 최소화:** CPU가 I/O 완료를 기다리지 않도록 비동기·병렬화

-   **중복 제거:** 불필요한 시스템 콜, 메모리 복사, 캐시 오염 제거

결국, I/O 최적화란 **CPU와 저장장치 간의 불균형을 줄이기 위한 구조적 접근**이다

### 2. Gensort에서 필요한 이유

Gensort는 **초대용량(수십~수백 GB)의 정렬 입력 데이터를 생성하는 도구**로, 전체 분산 정렬 파이프라인의 **첫 번째 병목 구간**을 담당함.
이 단계에서 I/O가 비효율적이면 이후 모든 단계(로컬 정렬, 샘플링, 워커 간 전송, 머지 정렬)가 전부 지연된다.
파일 쓰기/읽기 병목을 줄이면 **정렬 속도뿐 아니라 샘플링, 네트워크 송수신 효율**까지 함께 향상된다.

### 3. 주요 I/O 최적화 전략

1.  **Direct I/O:**

    -   커널 페이지 캐시를 우회하여 **사용자 버퍼 ↔ 디스크**로 곧바로 읽고/쓰는 모드.
        
    -   리눅스에서는 open(..., O_DIRECT)로 열고, 버퍼 주소/길이/오프셋을 보통 4096B(4KiB) 정렬로 맞춰야 한다.

2.  **병렬화 (스테이지 파이프라인 & 멀티스레드/K-way 머지 분할):**

    -   I/O와 CPU를 동시에 돌리기 위해 작업을 단계로 쪼개 파이프라인 구성:
        Disk Read → Parse/Partition → In-RAM Sort → Spill Write → (K-way Merge)

    -   각 단계는 전용 스레드/풀로 처리하고, 단계 간에는 lock-free/SPSC 큐로 청크를 넘긴다.

    -   입력 파일을 큰 청크(예: 256MiB~1GiB) 로 분할.
        단계별로 스레드풀 크기 고정 + in-flight 청크 수(2~4) 로 backpressure 관리.
        머지는 파티션별로 분리하고, 파티션마다 K-way 머지 스레드를 1개씩 두는 방식이 실전에서 안정적.
        
3.  **대규모 버퍼링 (N중 프리페치 & 대형 배치 Flush):** 

    -   입력: 2~4개의 큰 버퍼(예: 8~32MiB)를 프리페치하여 “읽는 동안 처리, 처리 중에도 읽기”가 가능하게 함.
        출력: 작은 레코드를 모아 큰 배치(예: 16~64MiB) 로 묶어 한 번에 write, 시스템콜 수를 최소화.

    -   입력은 N중(2~4), 출력은 하나의 큰 링 버퍼 + 가득 찰 때마다 flush.
        Direct I/O라면 버퍼 정렬/배수와 패딩을 항상 고려.

### 4. 각 전략의 장단점

  ---------------------------------------------------------------------------------------------------------------------------
  **전략**                 **장점**                                                 **단점**
  ----------------------- ----------------------- ----------------------------------------------------------------------------
  **Direct I/O**          - 페이지 캐시 우회로 시스템 캐시 오염 방지                    - 버퍼 주소·길이·오프셋 모두 4 KiB 정렬 필수
                          - 한 번 읽고 한 번 쓰는 워크로드에서 지속적인 I/O 속도 확보     - 작은 랜덤 I/O 에서는 비효율적
                          - 스필 파일 다수일 때 커널 write-back 폭주 방지              - 페이지 캐시 혜택(재사용, 리드-어헤드) 손실
                          - CPU 지연 변동 적음 (안정적인 Throughput)                  - 프로그래밍 복잡 (패딩·정렬 관리 필요)

  **병렬 파이프라인**       - 디스크 I/O 와 CPU 정렬을 동시에 수행 → 자원 100% 활용       - 스레드 과다 생성 시 컨텍스트 스위칭 오버헤드
                          - 코어 수 만큼 정렬/병합 병렬화 → CPU 효율 최대화             - 락/큐 경합으로 오히려 성능 저하 가능
                          - 네트워크·디스크 부하 분산 가능                             - NUMA 환경 비최적화 시 대역폭 낭비
                          - 지속적인 데이터 흐름으로 스톨 감소                          - 디버깅·동기화 복잡 (파이프라인 설계 필요)

  **대규모 버퍼링**         - 시스템콜 호출 횟수 감소 → 컨텍스트 스위칭 감소               - 버퍼 과대 할당 시 메모리 압박·GC 부담
                          - 큰 순차 I/O 로 디스크 처리량 극대화                        - Direct I/O 사용 시 버퍼 패딩 필요
                          - I/O 와 CPU 사이 파이프라인 지속성 유지                     - Flush 주기 잘못 잡으면 쓰기 스톨 발생
                          - Direct I/O 없이도 대부분의 I/O 효율 향상                  - 작업 크기·RAM 에 맞춘 튜닝 필수
  ----------------------------------------------------------------------------------------------------------------------------

### 5. Gensort 및 분산 정렬 시스템에서의 종합 활용

K-way Merge는 대규모 데이터 처리에서 다음과 같은 경우에 사용됩니다.

-   **입력 읽기 (GenSort 데이터 로딩):** 
    > Direct I/O + 대형 프리페치 버퍼를 이용
    > 커널 캐시 오염 없이 지속적인 순차 리드 성능 확보
-   **로컬 정렬 및 스필 생성:**
    > 병렬 파이프라인 + 대형 배치 Flush를 이용
    > CPU 정렬 과 디스크 쓰기를 동시에 수행, 스필 병목 감소
-   **로컬 정렬 및 스필 생성:**
    > 병렬 파티션 머지 + Direct I/O 출력 이용
    > 여러 런을 동시에 병합 하면서 일관된 Throughput 유지
-   **로컬 정렬 및 스필 생성:**
    > 파이프라인 + 버퍼링 (네트워크 ↔ 디스크)
    > 네트워크 수신과 디스크 기록 병렬화 → 엔드-투-엔드 스트리밍 성능 상승
